{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SB-PdM: a tool for predictive maintenance of rolling bearings based on limited labeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import asarray\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy.matlib\n",
    "from scipy import signal\n",
    "import scipy\n",
    "from scipy.fftpack import fft\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for FFT\n",
    "\n",
    "#Inputs:\n",
    "# x: input signal\n",
    "# fs: samplin freq. \n",
    "# num_samples = length of insput signal\n",
    "\n",
    "#Outputs:\n",
    "#f: freq. contents\n",
    "#freq_values: freq. spacing\n",
    "\n",
    "def apply_fft(x, fs, num_samples):\n",
    "    f = np.linspace(0.0, (fs/2.0), num_samples//2)\n",
    "    freq_values = fft(x)\n",
    "    freq_values = 2.0/num_samples * np.abs(freq_values[0:num_samples//2])\n",
    "    return f, freq_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perforem similarity-based_classification:\n",
    "# It applies similarity measures between reference samples and test samples.\n",
    "# The similarity measures are: Euclidean distance and cosine similarity.\n",
    "\n",
    "# Inputs: \n",
    "#baselines: features of labeled reference vibration segments\n",
    "#test_data: features of test vibration segments\n",
    "#baseline_labels: Labels of reference vibration segments\n",
    "\n",
    "# The function returns:\n",
    "#cos_s:  Cosine similarity  scores of test vibration segments \n",
    "#euc_s: Euclidean distance  scores of test vibration segments\n",
    "#y_cos:  Predicted classes using cosine similarity  scores of vibration segments \n",
    "#y_euc: Predicted classes using Euclidean distance\n",
    "\n",
    "def similarity_based_classification(baselines,test_data, baseline_labels):\n",
    "\n",
    "    cos_s = np.empty(len(test_data)) # Cosine similarity  scores of test smaples \n",
    "    euc_s = np.empty(len(test_data)) # Euclidean distance similarity  scores of test smaples\n",
    "    \n",
    "    y_cos = np.empty(len(test_data)) # Predicted classes using cosine similarity  scores of test smaples \n",
    "    y_euc = np.empty(len(test_data)) # Predicted classes using Euclidean distance\n",
    " \n",
    "    for i in range(len(test_data)):\n",
    "        s = test_data[i]\n",
    "        dist_record = np.empty(len(baselines))\n",
    "        dist2_record = np.empty(len(baselines))\n",
    "        for k in range(len(baselines)):\n",
    "            \n",
    "            dist_record[k] = distance.cosine(baselines[k].reshape(-1), test_data[i].reshape(-1)) # Cosine similaritiy\n",
    "            dist2_record[k] = np.mean( sum(abs(s1-s2)**2 for s1, s2 in zip( baselines[k], test_data[i] ))**(1/2) ) # Ecludian distance\n",
    "            \n",
    "        cos_s[i] = baseline_labels[int(np.argmin(dist_record))]\n",
    "        euc_s[i] = baseline_labels[int(np.argmin(dist2_record))]\n",
    "        y_cos[i] = np.min(cos_s) \n",
    "        y_euc[i] = np.min(euc_s)\n",
    "        \n",
    "    return cos_s, euc_s, y_cos, y_euc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==========================================================================================================================\n",
    "# Loading Data:\n",
    "\n",
    "## Note:\n",
    "\n",
    "### The vibratinon samples are extracted CWRU dataset. Link to  access the dataset: https://engineering.case.edu/bearingdatacenter\n",
    "\n",
    "=========================================================================================================================== "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of test & reference vibration samples: (3019, 2000)\n"
     ]
    }
   ],
   "source": [
    "## Load Test samples and thier labels from CSV file:\n",
    "df = pd.read_csv(\"./Test_Samples.csv\")\n",
    "y_test = df['labels'].to_numpy()\n",
    "test_data = df.drop(['labels'], axis=1).to_numpy()\n",
    "\n",
    "\n",
    "## Load Reference samples and thier labels from CSV file:\n",
    "df = pd.read_csv(\"./Reference_Samples.csv\")\n",
    "baselines_labels = df['labels'].to_numpy()\n",
    "baselines = df.drop(['labels'], axis=1).to_numpy()\n",
    "\n",
    "\n",
    "X = np.concatenate( (test_data, baselines) , axis=0, out=None) # Nummpy array contians test [samples:reference labels] for feature extraction\n",
    "print(\"Size of test & reference vibration samples:\", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2979, 2000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 12000 # Sample rate of vibration data.\n",
    "num_samples = X.shape[1] # number of datapoints in each vibration sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==========================================================================================================================\n",
    "# Feature Extraction:\n",
    "=========================================================================================================================== "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FFT features shape: (3019, 1000)\n",
      "STFT features shape: (3019, 515, 41)\n"
     ]
    }
   ],
   "source": [
    "# Note: Here, a noise-free scenario is considered.\n",
    "\n",
    "# FFT features extraction:\n",
    "fft_z = []\n",
    "for i in range(len(X)):\n",
    "    f, z = apply_fft(X[i], fs, num_samples)\n",
    "    fft_z.append(np.squeeze(np.asarray ( abs(z) ) ) )\n",
    "fft_features = np.asarray(fft_z, dtype=\"float\")\n",
    "print('FFT features shape:', fft_features.shape)\n",
    "\n",
    "# STFT features extraction:\n",
    "stft_z = []\n",
    "for i in range(len(X)):\n",
    "    f, t, z = signal.stft(X[i], fs, window='hamming', nperseg=(num_samples/2), noverlap=int( 0.95*(num_samples/2) ), nfft=1028)\n",
    "    stft_z.append(np.squeeze(np.asarray ( abs(z) ) ) )\n",
    "stft_features = np.asarray(stft_z, dtype=\"float\")\n",
    "print('STFT features shape:', stft_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select feature type: FFT features or STFT features\n",
    "features =  fft_features # ====>  fft_features / stft_features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==========================================================================================================================\n",
    "# Similarity-Based Classification:\n",
    "=========================================================================================================================== "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test samples size; (2979, 1000)\n",
      "Reference samples size; (40, 1000)\n",
      "Averaged Reference samples shape; (10, 1000)\n"
     ]
    }
   ],
   "source": [
    "# Separating features of test samples and reference samples and preparing for Similarity-based classification \n",
    "\n",
    "test_samples = features[:len(test_data)]\n",
    "print(\"Test samples size;\", test_samples.shape)\n",
    "baseline_samples = features[len(test_data):]\n",
    "print(\"Reference samples size;\", baseline_samples.shape)\n",
    "baselines_df = pd.DataFrame(data= baseline_samples.reshape(len(baseline_samples),-1) )\n",
    "baselines_df['labels']= baselines_labels\n",
    "\n",
    "# Averaging reference samples based on thier classes;\n",
    "# Since each class involves 4 different motor speeds. Refers to the paper for more details.\n",
    "baselines_features = baselines_df.groupby('labels').mean().to_numpy()\n",
    "y_ref_true = np.unique( baselines_labels, axis= 0)\n",
    "\n",
    "\n",
    "if np.sum(features) == np.sum(stft_features): # Reshape STFT features:\n",
    "    w, h = test_samples[0].shape\n",
    "    baselines_features = baselines_features.reshape(len(y_ref_true), w, h )\n",
    "    \n",
    "print(\"Averaged Reference samples shape;\", baselines_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarity-based classification\n",
    "y_pred_cos, y_pred_Ecl, cos_score, Ecl_score = similarity_based_classification(baselines_features, \n",
    "                                                                                               test_samples, y_ref_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==========================================================================================================================\n",
    "# Performance Metrics:\n",
    "=========================================================================================================================== "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.59718026183283 %\n",
      "Confusion Matrix:\n",
      "[[842   0   0   0   0   0   0   0   0   0]\n",
      " [  0 238   0   0   0   0   0   0   0   0]\n",
      " [  0   0 228   0   0   0   0   0   0   8]\n",
      " [  0   0   0 237   0   0   0   0   0   0]\n",
      " [  0   0   0   0 237   0   0   0   0   0]\n",
      " [  0   0   0   0   0 238   0   0   0   0]\n",
      " [  0   0   0   0   4   0 234   0   0   0]\n",
      " [  0   0   0   0   0   0   0 238   0   0]\n",
      " [  0   0   0   0   0   0   0   0 237   0]\n",
      " [  0   0   0   0   0   0   0   0   0 238]]\n"
     ]
    }
   ],
   "source": [
    "# Cosine similarity\n",
    "y_predicted = y_pred_cos\n",
    "accuracy =accuracy_score(y_test, y_predicted) \n",
    "conf_mat =confusion_matrix(y_test, y_predicted)\n",
    "print(\"Accuracy:\", accuracy*100, \"%\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.36220208123532 %\n",
      "Confusion Matrix:\n",
      "[[842   0   0   0   0   0   0   0   0   0]\n",
      " [  0 238   0   0   0   0   0   0   0   0]\n",
      " [  0   0 236   0   0   0   0   0   0   0]\n",
      " [  0   0   0 237   0   0   0   0   0   0]\n",
      " [  0   0   0   0 236   0   1   0   0   0]\n",
      " [  0   0   0   0   0 229   1   0   8   0]\n",
      " [  0   0   0   0   7   2 229   0   0   0]\n",
      " [  0   0   0   0   0   0   0 238   0   0]\n",
      " [  0   0   0   0   0   0   0   0 237   0]\n",
      " [  0   0   0   0   0   0   0   0   0 238]]\n"
     ]
    }
   ],
   "source": [
    "# Euclidean distance\n",
    "y_predicted = y_pred_Ecl\n",
    "accuracy =accuracy_score(y_test, y_predicted) \n",
    "conf_mat =confusion_matrix(y_test, y_predicted)\n",
    "print(\"Accuracy:\", accuracy*100, \"%\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_mat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
